run_name: ddpm
seed: 42
data_dir: ./data/imagenet100_128x128/train
image_size: 64
batch_size: 256
num_workers: 4
num_classes: 100
num_epochs: 50
learning_rate: 4e-4
weight_decay: 0.0
grad_clip: 1.0

# Mixed precision training
mixed_precision: "fp16"  # Options: "fp16", "bf16", "none"
gradient_accumulation_steps: 1

# Diffusion model parameters
num_train_timesteps: 500
num_inference_steps: 20
beta_start: 0.0001
beta_end: 0.02
beta_schedule: linear
variance_type: fixed_small
prediction_type: epsilon
clip_sample: True
clip_sample_range: 1.0

# Model architecture
unet_in_size: 16
unet_in_ch: 4
unet_ch: 64
unet_ch_mult: [1, 2, 4]
unet_attn: [1, 2]
unet_num_res_blocks: 2
unet_dropout: 0.1

# VAE settings - match the pretrained model architecture
vae_config:
  double_z: True
  z_channels: 4
  resolution: 256
  in_channels: 3
  out_ch: 3
  ch: 128
  ch_mult: [1, 2, 4]
  num_res_blocks: 2
  attn_resolutions: []
  dropout: 0.0

# Advanced features
use_ddim: False
latent_ddpm: True
use_cfg: False
cfg_guidance_scale: 3.0

# Output settings
output_dir: experiments

# Add these under training settings
warmup_epochs: 1
min_lr: 1e-6  # Minimum learning rate

# Add gradient checkpointing
use_gradient_checkpointing: False

# Add validation frequency
validation_freq: 1  # Validate every epoch instead of every 5 epochs